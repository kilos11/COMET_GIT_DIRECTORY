{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMExeWEjgkg56Y+cjK1WI4Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_9U_IVSXB3uT","executionInfo":{"status":"ok","timestamp":1719480941099,"user_tz":-120,"elapsed":15973,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"0d7f73c1-45d7-4d92-a2e7-4fde5f89216b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting comet_ml\n","  Downloading comet_ml-3.43.2-py3-none-any.whl (677 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/677.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/677.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m675.8/677.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.4/677.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml)\n","  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n","Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.19.2)\n","Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n","Collecting python-box<7.0.0 (from comet_ml)\n","  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet_ml)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.31.0)\n","Collecting semantic-version>=2.8.0 (from comet_ml)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting sentry-sdk>=1.1.0 (from comet_ml)\n","  Downloading sentry_sdk-2.7.0-py2.py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.1/300.1 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting simplejson (from comet_ml)\n","  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.0.7)\n","Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.14.1)\n","Collecting wurlitzer>=1.0.2 (from comet_ml)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n","  Downloading dulwich-0.22.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (979 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.1/979.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.7.1)\n","Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n","  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2024.6.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->everett[ini]<3.2.0,>=1.0.1->comet_ml) (1.16.0)\n","Installing collected packages: everett, wurlitzer, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n","  Attempting uninstall: python-box\n","    Found existing installation: python-box 7.2.0\n","    Uninstalling python-box-7.2.0:\n","      Successfully uninstalled python-box-7.2.0\n","Successfully installed comet_ml-3.43.2 configobj-5.0.8 dulwich-0.22.1 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-2.7.0 simplejson-3.19.2 wurlitzer-3.1.1\n"]}],"source":["!pip install comet_ml"]},{"cell_type":"code","source":["!git init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TXgiPyCyF2az","executionInfo":{"status":"ok","timestamp":1719481635994,"user_tz":-120,"elapsed":578,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"d759f11b-f07c-49e5-efd6-afed921b1e80"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/.git/\n"]}]},{"cell_type":"code","source":["!git branch -m COMET_GIT_DIRECTORY"],"metadata":{"id":"FoJdEBskF57N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Comet allows you to visualize images as logged assets, rendered graphics, or in custom panels—in an experiment and across experiments. Additionally, you can specify annotations including bounding boxes and/or masks when logging the image to support your specialized Computer Vision use case. Finally, consider logging additional metadata with each image to unlock the ability to group images by tag in the Comet UI.\n","\n","##The following method can be used to log images:\n","\n","`log_image()`.\n","##The following panel can be used to visualize images:\n","\n","`Image panel Chart`.\n","##In addition all the images logged to an Experiment can be view in the Single Experiment page tabs:\n","\n","`Graphics Tab`\n","`Assets & Artifacts Tab: images folder`."],"metadata":{"id":"19q5tTVjDMQ8"}},{"cell_type":"markdown","source":["#**Log image**#\n","##The examples below showcases how to log an example image of a bunny and loaded with PIL, as an array, or from filepath."],"metadata":{"id":"4EmiFY_6FB5C"}},{"cell_type":"code","source":["import io\n","import comet_ml\n","from PIL import Image\n","import requests\n","\n","# Initialize the Comet Experiment\n","comet_ml.init()\n","exp = comet_ml.Experiment()\n","\n","# Define an example image\n","image_url = \"https://cdn.pixabay.com/photo/2016/12/04/21/58/rabbit-1882699_1280.jpg\"\n","response = requests.get(image_url)\n","pil_image = Image.open(io.BytesIO(response.content))\n","\n","# Log image to Comet\n","exp.log_image(image_data=pil_image, name=\"example_pil\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIHsDRPMFXOO","executionInfo":{"status":"ok","timestamp":1719481683779,"user_tz":-120,"elapsed":4653,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"b75aa9cb-b640-40ed-cdde-0605d8816c3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : delicious_adhesive_2369\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/kilos11/general/8281191677ba42b1822a75036977f43e\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/kilos11/general/fec3e56243b444cb8d8ee2cc19af9083\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["{'web': 'https://www.comet.com/api/image/download?imageId=5f3bf1d346c045879bcc825ca30a0eeb&experimentKey=fec3e56243b444cb8d8ee2cc19af9083',\n"," 'api': 'https://www.comet.com/api/rest/v1/image/get-image?imageId=5f3bf1d346c045879bcc825ca30a0eeb&experimentKey=fec3e56243b444cb8d8ee2cc19af9083',\n"," 'imageId': '5f3bf1d346c045879bcc825ca30a0eeb'}"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["##When logging the image from array or file-like object, make sure that the image_channels argument correctly specify where the color channels is between first or last (default is last).\n","\n","##Additionally, the `log_image()` method allows you to specify other image options; for example, you could use the `image_scale` argument to rescale your image `(default is 1.0)` or the `image_colormap` argument to colorize the image data (default is None). Please refer to the method definition for a full list of arguments."],"metadata":{"id":"6OLT5V8EHL3s"}},{"cell_type":"markdown","source":["#**Log image with bounding boxes**#\n","##The example below showcases how to log images with bounding boxes which are used in Object Detection tasks.\n","\n","##The boxes, labels, and scores are created by running inference on the provided image with `fasterrcnn_resnet50_fpn` and taking the most confident prediction for each cat and dog in the image.\n","\n","##This code demonstrates how to use Comet ML to log an image with bounding box annotations, which is commonly used in object detection tasks. Here's a breakdown of what the code does:\n","\n","##1. It imports necessary libraries: `comet_ml` for experiment tracking, `PIL` for image processing, `requests` for downloading the image, and `io` for handling byte streams.\n","\n","##2. It initializes Comet ML and creates a new experiment for tracking.\n","\n","##3. It downloads an image from a specified URL and opens it using PIL.\n","\n","##4. It defines bounding boxes, labels, and confidence scores for objects detected in the image. In a real scenario, these would come from your object detection model's output.\n","\n","##5. It creates a structured annotations list that Comet ML can understand, containing the bounding box coordinates, labels, and scores for each detected object.\n","\n","##6. Finally, it logs the image along with its annotations to Comet ML using the `log_image` method.\n","\n","##This approach is particularly useful for visualizing and analyzing the performance of object detection models. By logging images with their predicted bounding boxes to Comet ML, you can easily inspect the model's predictions, track its performance over time, and share results with your team."],"metadata":{"id":"X5Wu7Si5HrX4"}},{"cell_type":"code","source":["import io\n","import comet_ml\n","from PIL import Image, ImageDraw\n","import requests\n","\n","# Initialize Comet ML for experiment tracking\n","comet_ml.init()\n","# Create a new Comet experiment\n","exp = comet_ml.Experiment()\n","\n","# Define the URL of the image we want to use\n","image_url = \"https://cdn.pixabay.com/photo/2018/10/01/09/21/pets-3715733_960_720.jpg\"\n","# Download the image\n","response = requests.get(image_url)\n","# Open the image using PIL (Python Imaging Library)\n","image = Image.open(io.BytesIO(response.content))\n","\n","# Define bounding boxes for objects in the image\n","# Each box is represented as [x1, y1, x2, y2]\n","boxes = [\n","    [626.9825439453125, 414.496826171875, 863.0851440429688, 599.9555053710938],\n","    [123.45330047607422, 307.92236328125, 286.8298034667969, 599.8884887695312],\n","    [428.3597717285156, 177.7510986328125, 647.4353637695312, 599.8512573242188],\n","    [224.74839782714844, 246.34512329101562, 431.33306884765625, 609.96240234375],\n","                ]\n","\n","# Define labels for each bounding box\n","labels = ['cat', 'dog', 'dog', 'cat']\n","\n","# Define confidence scores for each prediction\n","scores = [0.9971518516540527,\n","          0.9916735291481018,\n","          0.9886680245399475,\n","          0.9515751600265503]\n","\n","# Create a list of dictionaries containing annotation data\n","annotations_data = [\n","    {\"boxes\": [b], \"label\": l, \"score\": s} for b, l, s in zip(boxes, labels, scores)\n","]\n","\n","# Wrap the annotations data in a list with a name\n","annotations = [{\"name\": \"Predictions\", \"data\": annotations_data}]\n","\n","# Log the image with bounding boxes to Comet ML\n","exp.log_image(\n","    image_data=image,\n","    name=\"example-image-with-bounding-boxes.png\",\n","    annotations=annotations,\n","            )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zl8iuYu_K3j3","executionInfo":{"status":"ok","timestamp":1719483441357,"user_tz":-120,"elapsed":4638,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"30ee0a73-2249-4542-f74a-c02fe3423a66"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : static_waterfall_9232\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/kilos11/general/fec3e56243b444cb8d8ee2cc19af9083\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/kilos11/general/38af2d6716744650883dbdd89d2ed8d6\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["{'web': 'https://www.comet.com/api/image/download?imageId=113649a5368f42038c6965df0a1122ab&experimentKey=38af2d6716744650883dbdd89d2ed8d6',\n"," 'api': 'https://www.comet.com/api/rest/v1/image/get-image?imageId=113649a5368f42038c6965df0a1122ab&experimentKey=38af2d6716744650883dbdd89d2ed8d6',\n"," 'imageId': '113649a5368f42038c6965df0a1122ab'}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["#**Log image with regions**#\n","##The example below showcases how to log images with regions, also referred to as regions, which are used in Image Segmentation tasks.\n","\n","##The boxes, labels, and scores are created by running inference on the provided image with `maskrcnn_resnet50_fpn` and taking the most confident prediction for each cat and dog in the image.\n","\n","**This code demonstrates how to use Comet ML to log an image with region annotations, which is commonly used in instance segmentation tasks. Here's a breakdown of what the code does:**\n","\n","##1. It imports necessary libraries, including Comet ML for experiment tracking, PyTorch and torchvision for the object detection model, and various image processing libraries.\n","\n","##2. It initializes Comet ML and creates a new experiment for tracking.\n","\n","##3. It downloads an image from a specified URL and opens it using PIL.\n","\n","##4. The `get_regions` function is defined to perform instance segmentation on the image:\n","   - It uses a pre-trained Mask R-CNN model from torchvision.\n","      - The image is transformed into a tensor suitable for the model input.\n","         - The model predicts objects in the image, returning labels, scores, and segmentation masks.\n","            - The segmentation masks are converted to polygon points using the `_make_ped_points` helper function.\n","\n","            5. The `get_regions` function is called to obtain the points, labels, and scores for the detected objects.\n","\n","            6. The results are formatted into a structure that Comet ML can understand for annotation purposes.\n","\n","            7. Finally, it logs the image along with its region annotations to Comet ML using the `log_image` method.\n","\n","            This approach is particularly useful for visualizing and analyzing the performance of instance segmentation models. By logging images with their predicted regions to Comet ML, you can easily inspect the model's predictions, track its performance over time, and share results with your team.\n"],"metadata":{"id":"27Lk-FK0NoNI"}},{"cell_type":"code","source":["import comet_ml\n","import io\n","import numpy as np\n","from PIL import Image\n","import requests\n","from skimage import measure\n","import torch\n","import torchvision\n","from torchvision import transforms\n","\n","# Initialize Comet ML for experiment tracking\n","comet_ml.init()\n","# Create a new Comet experiment\n","exp = comet_ml.Experiment()\n","\n","# Define the URL of the image we want to use\n","image_url = \"https://cdn.pixabay.com/photo/2017/03/31/15/41/giraffe-2191662_960_720.jpg\"\n","# Download the image\n","response = requests.get(image_url)\n","# Open the image using PIL (Python Imaging Library)\n","image = Image.open(io.BytesIO(response.content))\n","\n","def get_regions(image):\n","    \"\"\"Returns points, scores, and labels for Comet image logging\"\"\"\n","\n","    def _make_ped_points(binary_mask):\n","        \"\"\"Converts binary mask labels to polygon point list\"\"\"\n","        # Find contours in the binary mask\n","        contours = measure.find_contours(binary_mask, 0.5)\n","        ped_points = []\n","\n","        for contour in contours:\n","            # Flip the contour coordinates and convert to a list\n","            contour = np.flip(contour, axis=1)\n","            segmentation = contour.ravel().tolist()\n","            ped_points.append(segmentation)\n","        return ped_points\n","\n","    # Load a pre-trained Mask R-CNN model\n","    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n","    model.eval()  # Set the model to evaluation mode\n","\n","    # Define image transformations for model input\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","                    ])\n","    # Apply transformations and add batch dimension\n","    image_tensor = transform(image).unsqueeze(0)\n","\n","    # Perform object detection\n","    with torch.no_grad():\n","        predictions = model(image_tensor)\n","\n","    # Extract labels, scores, and regions from predictions\n","    labels = predictions[0]['labels'].tolist()\n","    scores = predictions[0]['scores'].tolist()\n","    regions = predictions[0]['regions']\n","\n","    # Convert the regions to a polygon point list\n","    points = []\n","    for mask in predictions[0]['regions']:\n","        points.append(_make_ped_points(mask.numpy().squeeze())[0])\n","    return points, labels, scores\n","\n","# Get regions, labels, and scores from the image\n","points, labels, scores = get_regions(image)\n","\n","# Create a list of dictionaries containing annotation data\n","annotations_data = [\n","    {\"points\": [p], \"label\": l, \"score\": s} for p, l, s in zip(points, labels, scores)\n","    ]\n","\n","# Wrap the annotations data in a list with a name\n","annotations = [{\"name\": \"Predictions\", \"data\": annotations_data}]\n","\n","# Log the image with regions to Comet ML\n","exp.log_image(\n","    image_data=image,\n","    name=\"example-image-with-regions.png\",\n","    annotations=annotations,\n","            )"],"metadata":{"id":"pQb6COOgOPzp"},"execution_count":null,"outputs":[]},{"source":["import comet_ml\n","import io\n","import numpy as np\n","from PIL import Image\n","import requests\n","from skimage import measure\n","import torch\n","import torchvision\n","from torchvision import transforms\n","\n","# Initialize Comet ML for experiment tracking\n","comet_ml.init()\n","# Create a new Comet experiment\n","exp = comet_ml.Experiment()\n","\n","# Define the URL of the image we want to use\n","image_url = \"https://cdn.pixabay.com/photo/2017/03/31/15/41/giraffe-2191662_960_720.jpg\"\n","# Download the image\n","response = requests.get(image_url)\n","# Open the image using PIL (Python Imaging Library)\n","image = Image.open(io.BytesIO(response.content))\n","\n","def get_regions(image):\n","    \"\"\"Returns points, scores, and labels for Comet image logging\"\"\"\n","\n","    def _make_ped_points(binary_mask):\n","        \"\"\"Converts binary mask labels to polygon point list\"\"\"\n","        # Find contours in the binary mask\n","        contours = measure.find_contours(binary_mask, 0.5)\n","        ped_points = []\n","\n","        for contour in contours:\n","            # Flip the contour coordinates and convert to a list\n","            contour = np.flip(contour, axis=1)\n","            segmentation = contour.ravel().tolist()\n","            ped_points.append(segmentation)\n","        return ped_points\n","\n","    # Load a pre-trained Mask R-CNN model\n","    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n","    model.eval()  # Set the model to evaluation mode\n","\n","    # Define image transformations for model input\n","    transform = transforms.Compose([\n","    transforms.ToTensor(),\n","                    ])\n","    # Apply transformations and add batch dimension\n","    image_tensor = transform(image).unsqueeze(0)\n","\n","    # Perform object detection\n","    with torch.no_grad():\n","        predictions = model(image_tensor)\n","\n","    # Extract labels, scores, and masks from predictions\n","    # 'regions' key is not present, use 'masks' instead\n","    labels = predictions[0]['labels'].tolist()\n","    scores = predictions[0]['scores'].tolist()\n","    masks = predictions[0]['masks']  # Extract masks instead of regions\n","\n","    # Convert the masks to a polygon point list\n","    points = []\n","    for mask in masks:\n","        points.append(_make_ped_points(mask.numpy().squeeze())[0])\n","    return points, labels, scores\n","\n","# Get regions, labels, and scores from the image\n","points, labels, scores = get_regions(image)\n","\n","# Create a list of dictionaries containing annotation data\n","annotations_data = [\n","    {\"points\": [p], \"label\": l, \"score\": s} for p, l, s in zip(points, labels, scores)\n","    ]\n","\n","# Wrap the annotations data in a list with a name\n","annotations = [{\"name\": \"Predictions\", \"data\": annotations_data}]\n","\n","# Log the image with regions to Comet ML\n","exp.log_image(\n","    image_data=image,\n","    name=\"example-image-with-regions.png\",\n","    annotations=annotations,\n","            )"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RB6z5XCyUinR","executionInfo":{"status":"ok","timestamp":1719485502943,"user_tz":-120,"elapsed":22359,"user":{"displayName":"KGAOGELO Moloko","userId":"02299502165535871727"}},"outputId":"14ebbacc-148a-4e19-f0f1-6e4933c93757"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : considerable_auditor_2639\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/kilos11/general/4f5484d532714acdafaa7f106e8f0a32\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/kilos11/general/a274e04d04ad45da9265b8bca944a025\n","\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"execute_result","data":{"text/plain":["{'web': 'https://www.comet.com/api/image/download?imageId=8031e6394792421ea493612543b1b7a4&experimentKey=a274e04d04ad45da9265b8bca944a025',\n"," 'api': 'https://www.comet.com/api/rest/v1/image/get-image?imageId=8031e6394792421ea493612543b1b7a4&experimentKey=a274e04d04ad45da9265b8bca944a025',\n"," 'imageId': '8031e6394792421ea493612543b1b7a4'}"]},"metadata":{},"execution_count":9}]}]}